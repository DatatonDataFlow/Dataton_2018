{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lssro\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import string\n",
    "import gensim\n",
    "from stop_words import get_stop_words\n",
    "from itertools import chain\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from gensim import corpora, models\n",
    "import unidecode\n",
    "import io\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Archivos\n",
    "\n",
    "- Archivo de lematizacion: raiz de palabras\n",
    "- Archivo de transacciones\n",
    "- Archivo metadatos tabla transacciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo lematizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.open('lemmatization-es.txt', mode=\"r\", encoding=\"utf-8\")\n",
    "r_lemmatization=f.readlines()\n",
    "\n",
    "dic={}\n",
    "for i in r_lemmatization:\n",
    "    tmp=i.replace(\"\\n\",\"\").split(\"\\t\")\n",
    "    dic[tmp[1]]=tmp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11806137, 11)\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_csv('dt_trxpse_personas_2016_2018_muestra_adjt.csv', header= None,error_bad_lines=False,warn_bad_lines=False)\n",
    "print (a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.rename(columns={0:\"id_trn_ach\",1:\"id_cliente\",2:\"fecha\",\n",
    "                  3:\"hora\",4:\"valor_trx\",5:\"ref1\",6:\"ref2\",\n",
    "                  7:\"ref3\",8:\"sector\",9:\"subsector\",10:\"descripcion\",})  # asignacion de encabezados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadatos Transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_cliente</td>\n",
       "      <td>bigint</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_str</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ocupacion</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tipo_vivienda</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nivel_academico</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>estado_civil</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>genero</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>edad</td>\n",
       "      <td>int</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ingreso_rango</td>\n",
       "      <td>string</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    type  comment\n",
       "0       id_cliente  bigint      NaN\n",
       "1          seg_str  string      NaN\n",
       "2        ocupacion  string      NaN\n",
       "3    tipo_vivienda  string      NaN\n",
       "4  nivel_academico  string      NaN\n",
       "5     estado_civil  string      NaN\n",
       "6           genero  string      NaN\n",
       "7             edad     int      NaN\n",
       "8    ingreso_rango  string      NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data=pd.read_excel('Metadatos_Tabla.xlsx')\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trn_ach</th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>fecha</th>\n",
       "      <th>hora</th>\n",
       "      <th>valor_trx</th>\n",
       "      <th>ref1</th>\n",
       "      <th>ref2</th>\n",
       "      <th>ref3</th>\n",
       "      <th>sector</th>\n",
       "      <th>subsector</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230435642</td>\n",
       "      <td>3</td>\n",
       "      <td>20161207.0</td>\n",
       "      <td>113451</td>\n",
       "      <td>2122392.51</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222356110</td>\n",
       "      <td>10</td>\n",
       "      <td>20161016.0</td>\n",
       "      <td>3424</td>\n",
       "      <td>148438.37</td>\n",
       "      <td>Referencia:  Contrato:  Valor:</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309137749</td>\n",
       "      <td>10</td>\n",
       "      <td>20180120.0</td>\n",
       "      <td>195042</td>\n",
       "      <td>94025.19</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324614737</td>\n",
       "      <td>10</td>\n",
       "      <td>20180326.0</td>\n",
       "      <td>192146</td>\n",
       "      <td>94430.07000000001</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235344690</td>\n",
       "      <td>18</td>\n",
       "      <td>20170106.0</td>\n",
       "      <td>201317</td>\n",
       "      <td>670645.5699999999</td>\n",
       "      <td>MEDICINA PREPAGADA COLSANITAS</td>\n",
       "      <td>CE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>320049316</td>\n",
       "      <td>18</td>\n",
       "      <td>20180307.0</td>\n",
       "      <td>143513</td>\n",
       "      <td>706933.7</td>\n",
       "      <td>RECAUDO COLSANITAS</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>230519178</td>\n",
       "      <td>19</td>\n",
       "      <td>20161207.0</td>\n",
       "      <td>155840</td>\n",
       "      <td>306773.79</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>241307506</td>\n",
       "      <td>19</td>\n",
       "      <td>20170210.0</td>\n",
       "      <td>142809</td>\n",
       "      <td>701067.98</td>\n",
       "      <td>Pago de la Planilla Cesantias</td>\n",
       "      <td>CEDULA DE CIUDADANIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SERVICIOS FINANCIEROS</td>\n",
       "      <td>OTROS SERVICIOS FINANCIEROS</td>\n",
       "      <td>Otras actividades auxiliares de las actividade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>316193109</td>\n",
       "      <td>24</td>\n",
       "      <td>20180220.0</td>\n",
       "      <td>153148</td>\n",
       "      <td>767571.01</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>282076350</td>\n",
       "      <td>26</td>\n",
       "      <td>20170914.0</td>\n",
       "      <td>70026</td>\n",
       "      <td>100277.45</td>\n",
       "      <td>Pago de la factura # CONJUNTO RESIDENCIAL PIET...</td>\n",
       "      <td>IDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_trn_ach id_cliente       fecha    hora          valor_trx  \\\n",
       "0  230435642          3  20161207.0  113451         2122392.51   \n",
       "1  222356110         10  20161016.0    3424          148438.37   \n",
       "2  309137749         10  20180120.0  195042           94025.19   \n",
       "3  324614737         10  20180326.0  192146  94430.07000000001   \n",
       "4  235344690         18  20170106.0  201317  670645.5699999999   \n",
       "5  320049316         18  20180307.0  143513           706933.7   \n",
       "6  230519178         19  20161207.0  155840          306773.79   \n",
       "7  241307506         19  20170210.0  142809          701067.98   \n",
       "8  316193109         24  20180220.0  153148          767571.01   \n",
       "9  282076350         26  20170914.0   70026          100277.45   \n",
       "\n",
       "                                                ref1                  ref2  \\\n",
       "0                                                 CC                   NaN   \n",
       "1                     Referencia:  Contrato:  Valor:                    CC   \n",
       "2                                                 CC                   NaN   \n",
       "3                                                 CC                   NaN   \n",
       "4                      MEDICINA PREPAGADA COLSANITAS                    CE   \n",
       "5                                 RECAUDO COLSANITAS                    CC   \n",
       "6                                                 CC                   NaN   \n",
       "7                      Pago de la Planilla Cesantias  CEDULA DE CIUDADANIA   \n",
       "8                                                 CC                   NaN   \n",
       "9  Pago de la factura # CONJUNTO RESIDENCIAL PIET...                   IDC   \n",
       "\n",
       "   ref3                 sector                    subsector  \\\n",
       "0   NaN                     \\N                           \\N   \n",
       "1   NaN                     \\N                           \\N   \n",
       "2   NaN                     \\N                           \\N   \n",
       "3   NaN                     \\N                           \\N   \n",
       "4   NaN                     \\N                           \\N   \n",
       "5   NaN                     \\N                           \\N   \n",
       "6   NaN                     \\N                           \\N   \n",
       "7   NaN  SERVICIOS FINANCIEROS  OTROS SERVICIOS FINANCIEROS   \n",
       "8   NaN                     \\N                           \\N   \n",
       "9   NaN                     \\N                           \\N   \n",
       "\n",
       "                                         descripcion  \n",
       "0                                                 \\N  \n",
       "1                                                 \\N  \n",
       "2                                                 \\N  \n",
       "3                                                 \\N  \n",
       "4                                                 \\N  \n",
       "5                                                 \\N  \n",
       "6                                                 \\N  \n",
       "7  Otras actividades auxiliares de las actividade...  \n",
       "8                                                 \\N  \n",
       "9                                                 \\N  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de valores anomalos, con poca información o sin información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a[(a.valor_trx!=\"\\\\N\")]\n",
    "a=a[(a.ref1.isna()==False)|(a.ref2.isna()==False)|(a.ref3.isna()==False)|(a.descripcion!='\\\\N')|(a.sector!='\\\\N')|(a.subsector!='\\\\N')]\n",
    "a=a.replace(np.nan,'')\n",
    "a=a.replace('\\\\N','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción del texto\n",
    "\n",
    "extraemos la informacion contenida en las referencias (ref1,ref2,ref3) y se almacena en una sola columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= a.ref1.str.cat(a[\"ref2\"],sep='-')\n",
    "c= c.str.cat(a[\"ref3\"],sep='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liberación de memoria\n",
    "\n",
    "eliminamos las variables que ya no son útiles y llamamos la funcion gc.collect para liberar la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del a #eliminar variable\n",
    "gc.collect()# eliminar memoria que ocupaba la variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones para limpieza del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para remover puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Replace punctuation with tokens so we can use them in our model\n",
    "    text = text.replace('.', ' ')\n",
    "    text = text.replace(',', ' ')\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace(';', ' ')\n",
    "    text = text.replace('!', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace('(', ' ')\n",
    "    text = text.replace(')', ' ')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace('_', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace('#', ' ') \n",
    "    text = text.replace('$', ' ') \n",
    "    text = text.replace('%', ' ') \n",
    "    text = text.replace('/', ' ') \n",
    "    text = text.replace('*', ' ') \n",
    "    text = text.replace('+', ' ') \n",
    "    text = text.replace('<', ' ') \n",
    "    text = text.replace('>', ' ') \n",
    "    text = text.replace('=', ' ') \n",
    "    text = text.replace('@', ' ') \n",
    "    text = text.replace('[', ' ') \n",
    "    text = text.replace(']', ' ') \n",
    "    text = text.replace('^', ' ') \n",
    "    text = text.replace('`', ' ')\n",
    "    text = text.replace('{', ' ') \n",
    "    text = text.replace('}', ' ') \n",
    "    text = text.replace('~', ' ')\n",
    "    text = text.replace('|', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para eliminar signos de puntuación previamente definidos, convertir todos los caracteres a minúsculas y realizar una división de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()  # downcase\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para eliminar acentuaciones y stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in text:\n",
    "        try:\n",
    "            tmp=dic[token]\n",
    "        except:\n",
    "            tmp=token\n",
    "        if tmp not in stop_words:\n",
    "            tmp=unidecode.unidecode(tmp)\n",
    "            result.append(tmp)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de stop words\n",
    "\n",
    "Se importa libreria con la información de las stop words en el idioma español, se agregan a este listado palabras adicionales vistas en el conjunto de referencias y que carecen de sentido para el análisis.\n",
    "\n",
    "Estas stop words serán eliminadas del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('es')\n",
    "stop_words.append(\"pago\")\n",
    "stop_words.append(\"pse\")\n",
    "stop_words.append(\"referencia\")\n",
    "stop_words.append(\"ref\")\n",
    "stop_words.append(\"valor\")\n",
    "stop_words.append(\"fc\")\n",
    "stop_words.append(\"m\")\n",
    "stop_words.append(\"realizados\")\n",
    "stop_words.append(\"bog\")\n",
    "stop_words.append(\"agregado\")\n",
    "stop_words.append(\"numero\")\n",
    "stop_words.append(\"sc\")\n",
    "stop_words.append(\"idc\")\n",
    "stop_words.append(\"cr\")\n",
    "stop_words.append(\"d\")\n",
    "stop_words.append(\"cl\")\n",
    "stop_words.append(\"aa\")\n",
    "stop_words.append(\"sur\")\n",
    "stop_words.append(\"int\")\n",
    "stop_words.append(\"t\")\n",
    "stop_words.append(\"apoyo\")\n",
    "stop_words.append(\"saldar\")\n",
    "stop_words.append(\"pagar\")\n",
    "stop_words.append(\"sas\")\n",
    "stop_words.append(\"emcaliach\")\n",
    "stop_words.append(\"b\")\n",
    "stop_words.append(\"bogota\")\n",
    "stop_words.append(\"emcaliach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de stop words\n",
    "\n",
    "Se aplican las funciones de limpieza de texto por medio de apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= c.apply(my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs=c.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se libera memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del c\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de registros por palabra\n",
    "\n",
    "Se buscan los registros donde aparece una palabra determinada, con el fin de analizar con cuales otras palabras se relaciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in processed_docs:\n",
    "    if \"exito\" in i:\n",
    "        k=k+1\n",
    "        if k==3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traves', 'exito', 'cc']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i #registro donde aparece la palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listado de documentos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   [cc]\n",
       "1                           [referenciar, contratar, cc]\n",
       "2                                                   [cc]\n",
       "3                                                   [cc]\n",
       "4                 [medicinar, prepagada, colsanitas, ce]\n",
       "5                             [recaudar, colsanitas, cc]\n",
       "6                                                   [cc]\n",
       "7              [planilla, cesantias, cedula, ciudadania]\n",
       "8                                                   [cc]\n",
       "9      [facturar, conjuntar, residencial, pietra, san...\n",
       "10     [facturar, conjuntar, residencial, pietra, san...\n",
       "11                                  [plan, familiar, ce]\n",
       "12                                  [plan, familiar, ce]\n",
       "14                                                  [cc]\n",
       "15                                                  [cc]\n",
       "16                                                 [cpv]\n",
       "17                  [irecaudo, claro, solucionar, movil]\n",
       "18                    [facturar, asociar, bancoomevapfa]\n",
       "19                                                  [cc]\n",
       "20                                                  [cc]\n",
       "21                                                  [cc]\n",
       "22     [presentacion, imponer, predial, unificar, aaa...\n",
       "23                                  [edif, mirabell, ph]\n",
       "24                                  [edif, mirabell, ph]\n",
       "25                               [liquidacion, iuva, cc]\n",
       "26                                                    []\n",
       "27                                                  [cc]\n",
       "28                                                  [ce]\n",
       "29                                [referenciar, express]\n",
       "30                                [referenciar, express]\n",
       "                             ...                        \n",
       "73                [empresa, publicar, medellin, esp, ce]\n",
       "74      [comprar, valorizacion, medellin, fonvalmed, ce]\n",
       "75                                                    []\n",
       "76                [empresa, publicar, medellin, esp, cc]\n",
       "77                [empresa, publicar, medellin, esp, cc]\n",
       "78                            [recaudar, colsanitas, ce]\n",
       "79                                         [electronico]\n",
       "80                       [facturar, gas, natural, cupon]\n",
       "81                                                  [ce]\n",
       "82                                            [facturar]\n",
       "84                       [facturar, gas, natural, cupon]\n",
       "85                   [facturar, gas, natural, cupon, ce]\n",
       "86                                         [electronico]\n",
       "87                                                    []\n",
       "88                                                 [cpv]\n",
       "89                                                  [ce]\n",
       "90                                                    []\n",
       "91                                        [facturar, ce]\n",
       "92                            [recaudar, colegiar, tpni]\n",
       "93                                        [facturar, ce]\n",
       "94                             [contratar, facturar, ce]\n",
       "95                                            [facturar]\n",
       "96                                                  [cc]\n",
       "97                                                 [cpv]\n",
       "98                                                    []\n",
       "99                            [recaudar, apostillar, cc]\n",
       "100                           [recaudar, apostillar, cc]\n",
       "101                                                 [ce]\n",
       "102                                                 [ce]\n",
       "103                                                 [cc]\n",
       "Name: ref1, Length: 100, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir diccionario con las palabras únicas de los documentos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Muestra de las 10 primeras palabras del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cc\n",
      "1 contratar\n",
      "2 referenciar\n",
      "3 ce\n",
      "4 colsanitas\n",
      "5 medicinar\n",
      "6 prepagada\n",
      "7 recaudar\n",
      "8 cedula\n",
      "9 cesantias\n",
      "10 ciudadania\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de documentos que son tenidos en cuenta para la construcción del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11568871"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado del diccionario de palabras según análisis de frecuencias\n",
    "\n",
    "Se eliminan las palabras que no se presentan en más de 15 documentos y aquellas que estan en todos los documentos quedando con un total de 13165 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=1.0, keep_n=100000) \n",
    "# keep_n =100000 conserva sólo 100.000 de palabras en caso de que el diccionario tuviera mayor cantidad de palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteo de palabras por documento\n",
    "Por cada documento se crea una lista de las palabras que se encuentran en este y se cuenta las veces que aparece esa palabra en el mismo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vista del bag of words de un ejemplo de un documento preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 1), (25, 1), (26, 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[4310] #Ejemplo de documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 13 (\"facturar\") appears 1 time.\n",
      "Word 25 (\"asociar\") appears 1 time.\n",
      "Word 26 (\"bancoomevapfa\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Term frequency – Inverse document frequency (tfidf)\n",
    "\n",
    "weight_{i,j} = wlocal(frequency_{i,j}) * wglobal(document\\_freq_{i}, D)\n",
    "\n",
    "Análisis de la frecuencia de la palabra en el documento vs los documentos donde aparece la misma palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde, \n",
    "\n",
    "TF = (Número de veces que la palabra clave aparece en el documento) / (Número total de palabras en el documento)\n",
    "\n",
    "IDF = (Número total de documentos) / (Número total de veces que aparece la palabra en todos los documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo LDA\n",
    "Topic Modeling and Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling es un tipo de modelado estadístico que permite descubrir los temas abstractos que aparecen en una colección de documentos. \n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tópicos hallados en los documentos\n",
    "Se hallan las palabras que pertenecen a cada tema y su peso relativo, que explica el nivel de pertenencia de la palabra a cada tema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.636*\"cc\" + 0.059*\"falabella\" + 0.056*\"payu\" + 0.040*\"transaccional\" + 0.038*\"portal\" + 0.035*\"exito\" + 0.032*\"tarjeta\" + 0.031*\"visar\" + 0.025*\"credito\" + 0.019*\"amex\"\n",
      "Topic: 1 Word: 0.338*\"facturar\" + 0.094*\"cc\" + 0.072*\"suramericano\" + 0.032*\"tender\" + 0.032*\"comprar\" + 0.031*\"asociar\" + 0.031*\"bancoomevapfa\" + 0.025*\"virgin\" + 0.025*\"online\" + 0.025*\"polizas\"\n",
      "Topic: 2 Word: 0.101*\"cmr\" + 0.059*\"servicio\" + 0.054*\"avianca\" + 0.053*\"eticket\" + 0.051*\"facturar\" + 0.038*\"comerciar\" + 0.033*\"bogota\" + 0.033*\"virtual\" + 0.033*\"camara\" + 0.029*\"cc\"\n",
      "Topic: 3 Word: 0.144*\"postpago\" + 0.137*\"express\" + 0.088*\"facturar\" + 0.045*\"cc\" + 0.031*\"imponer\" + 0.027*\"tradicional\" + 0.023*\"vehiculos\" + 0.019*\"duplicar\" + 0.019*\"predial\" + 0.016*\"null\"\n",
      "Topic: 4 Word: 0.194*\"referenciar\" + 0.157*\"cpv\" + 0.128*\"contratar\" + 0.079*\"express\" + 0.074*\"electronico\" + 0.046*\"comprar\" + 0.042*\"cc\" + 0.026*\"tiquete\" + 0.015*\"paquete\" + 0.014*\"prestamo\"\n",
      "Topic: 5 Word: 0.150*\"traves\" + 0.092*\"certificar\" + 0.087*\"transaccion\" + 0.080*\"parir\" + 0.075*\"generacion\" + 0.073*\"libertar\" + 0.073*\"tradicion\" + 0.024*\"comprar\" + 0.024*\"exito\" + 0.022*\"boleteria\"\n",
      "Topic: 6 Word: 0.133*\"tpni\" + 0.109*\"nit\" + 0.052*\"hogar\" + 0.052*\"multiplay\" + 0.051*\"obligacion\" + 0.050*\"facturar\" + 0.029*\"etb\" + 0.028*\"periodo\" + 0.025*\"contar\" + 0.021*\"credito\"\n",
      "Topic: 7 Word: 0.236*\"recargar\" + 0.105*\"nequi\" + 0.038*\"recaudar\" + 0.034*\"cc\" + 0.024*\"linear\" + 0.021*\"datar\" + 0.021*\"flight\" + 0.021*\"psepayment\" + 0.020*\"cupon\" + 0.020*\"natural\"\n",
      "Topic: 8 Word: 0.111*\"cartero\" + 0.055*\"contractid\" + 0.055*\"addreess\" + 0.048*\"centilitro\" + 0.045*\"paymentid\" + 0.032*\"colombia\" + 0.029*\"interior\" + 0.027*\"seguro\" + 0.020*\"cc\" + 0.015*\"tag\"\n",
      "Topic: 9 Word: 0.128*\"publicar\" + 0.128*\"empresa\" + 0.127*\"esp\" + 0.123*\"medellin\" + 0.114*\"tipificar\" + 0.050*\"credito\" + 0.046*\"acces\" + 0.039*\"cc\" + 0.020*\"facturapayu\" + 0.018*\"ce\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se guarda el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.save('ldaref.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción nuevo documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = 'Pago de factura telefonia movil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pago', 'de', 'factura', 'telefonia', 'movil']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tokenizer(documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facturar', 'telefonia', 'movil']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(my_tokenizer(documento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 1), (23, 1), (5147, 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(preprocess(my_tokenizer(documento)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7749638557434082\t \n",
      "Topic: 0.133*\"tpni\" + 0.109*\"nit\" + 0.052*\"hogar\" + 0.052*\"multiplay\" + 0.051*\"obligacion\" + 0.050*\"facturar\" + 0.029*\"etb\" + 0.028*\"periodo\" + 0.025*\"contar\" + 0.021*\"credito\"\n",
      "\n",
      "Score: 0.025022879242897034\t \n",
      "Topic: 0.338*\"facturar\" + 0.094*\"cc\" + 0.072*\"suramericano\" + 0.032*\"tender\" + 0.032*\"comprar\" + 0.031*\"asociar\" + 0.031*\"bancoomevapfa\" + 0.025*\"virgin\" + 0.025*\"online\" + 0.025*\"polizas\"\n",
      "\n",
      "Score: 0.02500748820602894\t \n",
      "Topic: 0.101*\"cmr\" + 0.059*\"servicio\" + 0.054*\"avianca\" + 0.053*\"eticket\" + 0.051*\"facturar\" + 0.038*\"comerciar\" + 0.033*\"bogota\" + 0.033*\"virtual\" + 0.033*\"camara\" + 0.029*\"cc\"\n",
      "\n",
      "Score: 0.025005053728818893\t \n",
      "Topic: 0.144*\"postpago\" + 0.137*\"express\" + 0.088*\"facturar\" + 0.045*\"cc\" + 0.031*\"imponer\" + 0.027*\"tradicional\" + 0.023*\"vehiculos\" + 0.019*\"duplicar\" + 0.019*\"predial\" + 0.016*\"null\"\n",
      "\n",
      "Score: 0.02500056102871895\t \n",
      "Topic: 0.236*\"recargar\" + 0.105*\"nequi\" + 0.038*\"recaudar\" + 0.034*\"cc\" + 0.024*\"linear\" + 0.021*\"datar\" + 0.021*\"flight\" + 0.021*\"psepayment\" + 0.020*\"cupon\" + 0.020*\"natural\"\n",
      "\n",
      "Score: 0.025000175461173058\t \n",
      "Topic: 0.111*\"cartero\" + 0.055*\"contractid\" + 0.055*\"addreess\" + 0.048*\"centilitro\" + 0.045*\"paymentid\" + 0.032*\"colombia\" + 0.029*\"interior\" + 0.027*\"seguro\" + 0.020*\"cc\" + 0.015*\"tag\"\n",
      "\n",
      "Score: 0.02500000223517418\t \n",
      "Topic: 0.636*\"cc\" + 0.059*\"falabella\" + 0.056*\"payu\" + 0.040*\"transaccional\" + 0.038*\"portal\" + 0.035*\"exito\" + 0.032*\"tarjeta\" + 0.031*\"visar\" + 0.025*\"credito\" + 0.019*\"amex\"\n",
      "\n",
      "Score: 0.02500000223517418\t \n",
      "Topic: 0.194*\"referenciar\" + 0.157*\"cpv\" + 0.128*\"contratar\" + 0.079*\"express\" + 0.074*\"electronico\" + 0.046*\"comprar\" + 0.042*\"cc\" + 0.026*\"tiquete\" + 0.015*\"paquete\" + 0.014*\"prestamo\"\n",
      "\n",
      "Score: 0.02500000223517418\t \n",
      "Topic: 0.150*\"traves\" + 0.092*\"certificar\" + 0.087*\"transaccion\" + 0.080*\"parir\" + 0.075*\"generacion\" + 0.073*\"libertar\" + 0.073*\"tradicion\" + 0.024*\"comprar\" + 0.024*\"exito\" + 0.022*\"boleteria\"\n",
      "\n",
      "Score: 0.02500000223517418\t \n",
      "Topic: 0.128*\"publicar\" + 0.128*\"empresa\" + 0.127*\"esp\" + 0.123*\"medellin\" + 0.114*\"tipificar\" + 0.050*\"credito\" + 0.046*\"acces\" + 0.039*\"cc\" + 0.020*\"facturapayu\" + 0.018*\"ce\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[dictionary.doc2bow(preprocess(my_tokenizer(documento)))], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.025000002),\n",
       " (1, 0.025020648),\n",
       " (2, 0.025007486),\n",
       " (3, 0.025005052),\n",
       " (4, 0.025000002),\n",
       " (5, 0.025000002),\n",
       " (6, 0.77496606),\n",
       " (7, 0.025000561),\n",
       " (8, 0.025000175),\n",
       " (9, 0.025000002)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_tfidf[dictionary.doc2bow(preprocess(my_tokenizer(documento)))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
